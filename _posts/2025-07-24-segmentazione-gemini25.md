---
title: "Segmentazione conversazionale con Gemini 2.5: cosa vede davvero lâ€™IA?"
date: 2025-07-24
author: alessio
classes: wide
header:
  overlay_image: /assets/images/gemini-cupcakes_with_bbox.png
  overlay_filter: 0.6
---

> Lâ€™intelligenza artificiale non si limita piÃ¹ a riconoscere oggetti generici come â€œpersonaâ€ o â€œautoâ€. Con [Gemini 2.5](https://developers.googleblog.com/en/conversational-image-segmentation-gemini-2-5/), possiamo descrivere scenari complessi in linguaggio naturale e ottenere risposte visive su misura. Ecco due esempi pratici di come puÃ² essere utile nella vita reale.

## ğŸ§  Cosâ€™Ã¨ la segmentazione conversazionale?

La segmentazione conversazionale permette di selezionare *solo* ciÃ² che ci interessa in unâ€™immagine, usando descrizioni naturali come:

- â€œoggetti che potrebbero causare danni al tagliaerba automaticoâ€
- â€œaree danneggiate visibili nella scenaâ€
- â€œoggetti sul prato, ma **non** su quello sinteticoâ€

Il sistema risponde evidenziando le porzioni esatte dellâ€™immagine, andando ben oltre i classici â€œbounding boxâ€ rettangolari.

## ğŸ’¡ Caso dâ€™uso 1 â€“ Identificazione di un rischio elettrico

<a href="/assets/images/segmentazione-gemini/plafoniera-rotta.png" target="_blank">
  <img src="/assets/images/segmentazione-gemini/plafoniera-rotta.png" alt="Plafoniera danneggiata" />
</a>

In questa immagine, la richiesta al modello Ã¨:

> â€œMostrami gli oggetti che rappresentano una minaccia per la sicurezza.â€

Il modello evidenzia una **plafoniera danneggiata con cablaggi esposti**, potenzialmente pericolosa in caso di pioggia. Questo tipo di analisi puÃ² essere automatizzato in ambito sicurezza, manutenzione o ispezione remota di impianti.

## ğŸŒ± Caso dâ€™uso 2 â€“ Preparazione automatica del giardino prima del taglio

**Contesto:**  
Un sistema di sorveglianza monitora il giardino. Prima che parta il tagliaerba automatico, vogliamo sapere se ci sono oggetti lasciati sullâ€™erba che potrebbero essere danneggiati o incastrarsi nelle lame.

### ğŸ“¸ Immagine 1 â€“ Situazione iniziale

<a href="/assets/images/segmentazione-gemini/giardino-iniziale.png" target="_blank">
  <img src="/assets/images/segmentazione-gemini/giardino-iniziale.png" alt="Giardino ripreso da videocamera" />
</a>

Prompt dato al modello:

> â€œSegnala oggetti sullâ€™erba (escludendo lâ€™erba sintetica) che potrebbero essere danneggiati dalle lame del tagliaerba.â€

### âœ… Risultato del modello

<a href="/assets/images/segmentazione-gemini/giardino-segmentato.png" target="_blank">
  <img src="/assets/images/segmentazione-gemini/giardino-segmentato.png" alt="Oggetti pericolosi evidenziati" />
</a>

Notare come:

- Gli oggetti **sul prato sintetico** (area in alto a sinistra) **vengono ignorati**
- Gli oggetti troppo grandi (come il palo con luce a destra) non vengono segnalati, perchÃ© non rappresentano una minaccia per le lame
- Vengono invece individuati i piccoli coni in plastica arancione sul prato, potenzialmente dannosi (e danneggiabili...) se raggiunti dal robot

Questa logica permette di attivare notifiche automatiche allâ€™utente, migliorando sicurezza ed efficienza del sistema.

## ğŸš€ Conclusioni

La segmentazione conversazionale di Gemini 2.5 trasforma unâ€™immagine in unâ€™interfaccia interattiva: basta una frase, e lâ€™IA risponde visivamente. Con applicazioni che spaziano dalla sicurezza alla domotica, questo tipo di intelligenza visiva apre scenari molto concreti anche per sviluppatori e maker.

